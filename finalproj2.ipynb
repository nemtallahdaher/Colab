{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nemtallahdaher/Colab/blob/main/finalproj2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePYdsxyewtDB"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d anilkrsah/deepmushroom\n",
        "! kaggle datasets download -d maysee/mushrooms-classification-common-genuss-images\n",
        "! kaggle datasets download -d mustai/mushroom-12-9528\n",
        "! mkdir train\n",
        "! unzip deepmushroom.zip -d train\n",
        "#! unzip mushrooms-classification-common-genuss-images.zip -d datasets\n",
        "#! unzip mushroom-12-9528.zip -d datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_hk2w0LSgDX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "3675e48d-b32c-40d8-9fa8-b7e0a4560ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   334] loss: 7.296\n",
            "[2,   334] loss: 6.858\n",
            "[3,   334] loss: 6.401\n",
            "[4,   334] loss: 6.125\n",
            "[5,   334] loss: 5.869\n",
            "[6,   334] loss: 5.581\n",
            "[7,   334] loss: 5.288\n",
            "[8,   334] loss: 4.916\n",
            "[9,   334] loss: 4.443\n",
            "[10,   334] loss: 3.873\n",
            "Finished Training\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAR5UlEQVR4nO3debBkZX3G8e8Dg0RWDVwBARlcCktNUBwVhFAG0LgQsCIlqChQJKgV1xANJJa7VlxiocaYIiCgIBBxCVAuKIpgFvQOjIqAigZkEOQiyqKooL/80WfI5XJnpuc63ef2vN9P1a3ps0y/T5+qeebct7vPSVUhSWrHRn0HkCSNl8UvSY2x+CWpMRa/JDXG4pekxlj8ktQYi18TI8m1SQ4Y01gPTHJektuSfGIcY84a+ztJnjbOMdWWJX0HkBapQ4DtgG2q6p5RDZLkVGBlVb1h1bqqeuyoxpPAM35pdXYBvjfK0pf6YvFrIiXZNMkJSX7c/ZyQZNNu27ZJzk/y8yS3JrkkyUbdtr9LckOSO5J8N8n+8zz3W4A3AocmuTPJ0UnenOT0WfssTVJJlnTLFyV5W5L/7J77giTbztp/nyT/1WW6PsmRSY4BXgS8vhvnvG7fe6e01vI6n5ZkZZJjk9yc5MYkR43qmGvDYfFrUv0DsCfweGB34MnAqumSY4GVwBSD6Zq/ByrJbsArgCdV1ZbAnwHXzn3iqnoT8E7g7KraoqpOHjLTC4GjgIcADwD+FiDJLsDngA92mR4PrKiqE4EzgHd34/z5Or5OgO2BrYEdgaOBDyV58JB51SiLX5PqRcBbq+rmqpoB3gK8uNt2N7ADsEtV3V1Vl9TgolS/BTYFHpNkk6q6tqp+sB4znVJV36uqu4B/Z1DWMPgP4UtVdWaX56dVtWLI51zT64TBa31r97yfBe4Edls/L0cbKotfk+qhwHWzlq/r1gG8B7gGuCDJD5McB1BV1wCvAd4M3JzkrCQPZf25adbjXwJbdI93Bhb6H8yaXifAT+e8DzF7XGleFr8m1Y8ZvAG7ysO6dVTVHVV1bFU9HDgI+JtVc/lV9fGq2qf7uwW8a8jxfgFsNmt5+3XIej3wiNVsW9vlcVf7OqWFsvg1qc4E3pBkqnsT9Y3A6QBJDkzyyCQBbmMwxfO7JLsl2a97c/RXwF3A74YcbwWwb5KHJdkaOH4dsp4BHJDk+UmWJNkmyappoJ8AD1/I65QWyuLXpHo7MA18C/g2cFm3DuBRwJcYzHf/N/AvVfUVBvP7/wjcwmBa5iEMWeBV9UXg7G685cD5wwatqh8Bz2bwpvOtDP4T2b3bfDKD9xx+nuQz6/g6pQWJN2KRpLZ4xi9JjbH4JakxFr8kNcbil6TGTMTVObfddttaunRp3zEkaaIsX778lqqamrt+Iop/6dKlTE9P9x1DkiZKkuvmW+9UjyQ1xuKXpMZY/JLUGItfkhpj8UtSY0ZW/Ek+0t0O7opZ6/4wyReTfL/70zsFSdKYjfKM/1TgmXPWHQdcWFWPAi7sliVJYzSy4q+qixlcgna2g4HTusenAc8d1fiSpPmNe45/u6q6sXt8E4MbYc8ryTFJppNMz8zMjCedJDWgtzd3u5tfr/ZmAFV1YlUtq6plU1P3+8axJGmBxl38P0myA0D3581jHl+Smjfu4j8XOKJ7fATwH2MeX5KaN8qPc57J4H6nuyVZmeRoBvc7fXqS7wMHdMuSpDEa2dU5q+oFq9m0/6jGlCStnd/claTGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGtNL8Sd5bZLvJLkiyZlJ/qCPHJLUorEXf5IdgVcBy6rqccDGwGHjziFJreprqmcJ8MAkS4DNgB/3lEOSmjP24q+qG4D3Aj8CbgRuq6oL5u6X5Jgk00mmZ2Zmxh1TkjZYfUz1PBg4GNgVeCiweZLD5+5XVSdW1bKqWjY1NTXumJK0wepjqucA4H+raqaq7gY+BTy1hxyS1KQ+iv9HwJ5JNksSYH/gqh5ySFKT+pjjvxQ4B7gM+HaX4cRx55CkVi3pY9CqehPwpj7GlqTW+c1dSWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY2x+CWpMUMVf5J3J9kqySZJLkwyk+TwhQ6a5EFJzklydZKrkuy10OeSJK2bYc/4n1FVtwMHAtcCjwRe93uM+37g81X1aGB34Krf47kkSetgyTru9xzgE1V1W5IFDZhka2Bf4EiAqvoN8JsFPZkkaZ0Ne8Z/fpKrgScCFyaZAn61wDF3BWaAU5JcnuSkJJvP3SnJMUmmk0zPzMwscChJ0lxDFX9VHQc8FVhWVXcDvwAOXuCYS4A9gA9X1RO65zpunjFPrKplVbVsampqgUNJkuYadqoH4NHA0iSz/85HFzDmSmBlVV3aLZ/DPMUvSRqNoYo/yceARwArgN92q4sFFH9V3ZTk+iS7VdV3gf2BK9f1eSRJCzPsGf8y4DFVVetp3FcCZyR5APBD4Kj19LySpLUYtvivALYHblwfg1bVCgb/mUiSxmyNxZ/kPAZTOlsCVyb5OvDrVdur6qDRxpMkrW9rO+N/71hSSJLGZo3FX1VfBUiyK3BjVf2qW34gsN3o40mS1rdhv8D1CeB3s5Z/262TJE2YYYt/SXdpBeDeyyw8YDSRJEmjNGzxzyS5943cJAcDt4wmkiRplIb9OOfLGHzu/kPd8vXAi0cTSZI0SkMVf1X9ANgzyRbd8p0jTSVJGplhb8SydZL3ARcBFyX5p+7yypKkCTPsHP9HgDuA53c/twOnjCqUJGl0hp3jf0RVPW/W8luSrBhFIEnSaA17xn9Xkn1WLSTZG7hrNJEkSaM07Bn/y4HTunn9ALcCR4wslSRpZIb9VM8KYPckW3XLt480lSRpZIb9VM82ST7A4FM9X0ny/iTbjDSZJGkkhp3jP4vBDdKfBxzSPT57VKEkSaMz7Bz/DlX1tlnLb09y6CgCSZJGa9gz/guSHJZko+7n+cAXRhlMkjQawxb/XwFnMLj71q8ZTP28NMkdSXyjV5ImyLDFvzVwJPC2qtoEWAocUFVbVtVWI8omSRqBYYv/Q8CewAu65TuAfx5JIknSSA375u5TqmqPJJcDVNXPkngjFkmaQMOe8d+dZGOgAJJMcd9bMUqSJsSwxf8B4NPAQ5K8A/ga8M6RpZIkjcywl2w4I8lyYH8G1+p5blVdNdJkkqSRGHaOn6q6Grh6hFkkSWMw7FSPJGkDYfFLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGtNb8SfZOMnlSc7vK4MktajPM/5XA17vR5LGrJfiT7IT8BzgpD7Gl6SW9XXGfwLwetZwTf8kxySZTjI9MzMzvmSStIEbe/EnORC4uaqWr2m/qjqxqpZV1bKpqakxpZOkDV8fZ/x7AwcluRY4C9gvyek95JCkJo29+Kvq+KraqaqWAocBX66qw8edQ5Ja5ef4JakxQ9+BaxSq6iLgoj4zSFJrPOOXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaM/biT7Jzkq8kuTLJd5K8etwZJKllS3oY8x7g2Kq6LMmWwPIkX6yqK3vIIknNGfsZf1XdWFWXdY/vAK4Cdhx3DklqVa9z/EmWAk8ALp1n2zFJppNMz8zMjDuaJG2weiv+JFsAnwReU1W3z91eVSdW1bKqWjY1NTX+gJK0geql+JNswqD0z6iqT/WRQZJa1cenegKcDFxVVe8b9/iS1Lo+zvj3Bl4M7JdkRffz7B5ySFKTxv5xzqr6GpBxjytJGvCbu5LUGItfkhpj8UtSYyx+SWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhqTquo7w1olmQGuG8NQ2wK3jGGc9WnSMk9aXpi8zJOWFyYv86Tk3aWqpuaunIjiH5ck01W1rO8c62LSMk9aXpi8zJOWFyYv86TlncupHklqjMUvSY2x+O/rxL4DLMCkZZ60vDB5mSctL0xe5knLex/O8UtSYzzjl6TGWPyS1Jhmiz/JxkkuT3L+PNs2TXJ2kmuSXJpk6fgT3i/TmvIemWQmyYru5y/7yDgn07VJvt3lmZ5ne5J8oDvG30qyRx8552RaW+anJblt1nF+Yx85Z+V5UJJzklyd5Koke83ZvqiO8RB5F9vx3W1WlhVJbk/ymjn7LKpjPKwlfQfo0auBq4Ct5tl2NPCzqnpkksOAdwGHjjPcPNaUF+DsqnrFGPMM40+ranVfcnkW8Kju5ynAh7s/+7amzACXVNWBY0uzZu8HPl9VhyR5ALDZnO2L7RivLS8souNbVd8FHg+DEy/gBuDTc3ZbbMd4KE2e8SfZCXgOcNJqdjkYOK17fA6wf5KMI9t8hsg7iQ4GPloD/wM8KMkOfYeaFEm2BvYFTgaoqt9U1c/n7LZojvGQeRez/YEfVNXcKwgsmmO8LposfuAE4PXA71azfUfgeoCquge4DdhmPNHmtba8AM/rftU8J8nOY8q1JgVckGR5kmPm2X7vMe6s7Nb1aW2ZAfZK8s0kn0vy2HGGm2NXYAY4pZsCPCnJ5nP2WUzHeJi8sHiO71yHAWfOs34xHeOhNVf8SQ4Ebq6q5X1nGcaQec8DllbVHwNf5P9/W+nTPlW1B4Nfhf86yb59BxrC2jJfxuDaJ7sDHwQ+M+6AsywB9gA+XFVPAH4BHNdjnrUZJu9iOr736qalDgI+0XeW9aW54gf2Bg5Kci1wFrBfktPn7HMDsDNAkiXA1sBPxxlylrXmraqfVtWvu8WTgCeON+L9VdUN3Z83M5gXffKcXe49xp2dunW9WVvmqrq9qu7sHn8W2CTJtmMPOrASWFlVl3bL5zAo1tkW0zFea95FdnxnexZwWVX9ZJ5ti+kYD6254q+q46tqp6payuDXty9X1eFzdjsXOKJ7fEi3Ty/fdBsm75w5xYMYvAncmySbJ9ly1WPgGcAVc3Y7F3hJ96mIPYHbqurGMUe91zCZk2y/6r2eJE9m8O+nlxOCqroJuD7Jbt2q/YEr5+y2aI7xMHkX0/Gd4wXMP80Di+gYr4uWP9VzH0neCkxX1bkM3oD6WJJrgFsZFO6iMifvq5IcBNzDIO+RfWYDtgM+3f0bXgJ8vKo+n+RlAFX1r8BngWcD1wC/BI7qKesqw2Q+BHh5knuAu4DD+joh6LwSOKObivghcNQiP8Zry7vYju+qk4CnAy+dtW4xH+OheMkGSWpMc1M9ktQ6i1+SGmPxS1JjLH5JaozFL0mNsfilNUhyZ98ZpPXN4pekxlj80hC6b2a+J8kVGVyz/9Bu/Q5JLu6u135Fkj/J4N4Jp87a97V955dm85u70nD+gsG12XcHtgW+keRi4IXAF6rqHd012zfr9tuxqh4HgxuQ9JRZmpdn/NJw9gHOrKrfdhfr+irwJOAbDC498Gbgj6rqDgaXI3h4kg8meSZwe1+hpflY/NLvoaouZnCDkRuAU5O8pKp+xuA3g4uAl7Fh3UBHGwCLXxrOJcCh3fz9FIOy/3qSXYCfVNW/MSj4PbpLCW9UVZ8E3sD9L5cs9co5fmk4nwb2Ar7J4E5dr6+qm5IcAbwuyd3AncBLGNyB6ZQkq06sju8jsLQ6Xp1TkhrjVI8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY35P5oYLcxPwbx0AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "cuda0 = torch.device('cuda:0')\n",
        "########################################################################\n",
        "#\n",
        "transform1 = transforms.Compose([transforms.ToTensor(),transforms.Resize((227,227))])\n",
        "\n",
        "batch_size = 20\n",
        "\n",
        "dataset = torchvision.datasets.ImageFolder(root='/content/datasets/Mushrooms_3dataset(9528)/train', transform=transform1)\n",
        "#trainset,testset = torch.utils.data.random_split(dataset, [8583, 950])\n",
        "trainloader1 = torch.utils.data.DataLoader(dataset, batch_size=batch_size,shuffle=True, num_workers=4)\n",
        "\n",
        "classes = ('Agaricus', 'Amanita', 'Boletus', 'Cortinarius','Entoloma', 'Exidia', 'Hygrocybe', 'Inocybe', 'Lactarius', 'Pluteus', 'Russula', 'Suillus')\n",
        "\n",
        "\n",
        "########################################################################\n",
        "# 2. Define a Convolutional Neural Network\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes=12):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.num_classes = num_classes\n",
        "        # convolutional layers\n",
        "        self.conv1 = nn.Conv2d(self.in_channels, out_channels=96, kernel_size= 11, stride=4, padding=0)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride= 1, padding= 2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride= 1, padding= 1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1  = nn.Linear(in_features= 9216, out_features=4096)\n",
        "        self.fc2  = nn.Linear(in_features=4096, out_features=4096)\n",
        "        self.fc3 = nn.Linear(in_features=4096 , out_features=self.num_classes)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.maxpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = AlexNet(in_channels=3, num_classes=12)\n",
        "net2 = AlexNet(in_channels=1, num_classes=12)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "    net2.cuda()\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes=12):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.num_classes = num_classes\n",
        "        self.conv1 = nn.Conv2d(self.in_channels, 6, 5)     #input channel: 1, output channel: 6, filter: 5x5\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, out_features=self.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = torch.flatten(x, 1)     # flatten all dimensions except the batch dimension\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net3 = LeNet(in_channels=3, num_classes=12)\n",
        "if torch.cuda.is_available():\n",
        "    net3.cuda()\n",
        "########################################################################\n",
        "# 3. Define a Loss function and optimizer\n",
        "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "# Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
        "\n",
        "import torch.optim as optim\n",
        "from itertools import chain\n",
        "\n",
        "ce = nn.CrossEntropyLoss()\n",
        "\n",
        "o3 = optim.Adam(net3.parameters(), lr=0.0001)\n",
        "o2 = optim.Adam(chain(net2.parameters(), net3.parameters()), lr=0.0001)\n",
        "o1 = optim.Adam(chain(net.parameters(), net2.parameters(),net3.parameters()), lr=0.0001)\n",
        "\n",
        "\n",
        "########################################################################\n",
        "# 4. Train the network\n",
        "# ^^^^^^^^^^^^^^^^^^^^\n",
        "#\n",
        "# This is when things start to get interesting.\n",
        "# We simply have to loop over our data iterator, and feed the inputs to the\n",
        "# network and optimize.\n",
        "\n",
        "# loop over the dataset multiple times\n",
        "for epoch in range(10):\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(trainloader1, 0):\n",
        "\n",
        "    # get the inputs; data is a list of [inputs, labels]\n",
        "    inputs, labels = data\n",
        "    if torch.cuda.is_available():\n",
        "      inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    o3.zero_grad()\n",
        "    o2.zero_grad()\n",
        "    o1.zero_grad()\n",
        "\n",
        "    # get a gray image of the original\n",
        "    grey_inputs = transforms.Grayscale()(inputs)\n",
        "\n",
        "    # get a 32x32 image of the gray image\n",
        "    #small_grey_inputs = transforms.Resize((32,32))(grey_inputs)\n",
        "\n",
        "    # get a 32x32 image of the color image\n",
        "    small_inputs = transforms.Resize((32,32))(inputs)\n",
        "\n",
        "    # forward\n",
        "    outputs = net(inputs)\n",
        "    outputs2 = net2(grey_inputs)\n",
        "    outputs3 = net3(small_inputs)\n",
        "\n",
        "    # loss function for all images\n",
        "    lossNet = ce(outputs, labels)\n",
        "    lossNet2 = ce(outputs2, labels)\n",
        "    lossNet3 = ce(outputs3, labels)\n",
        "    loss = lossNet + lossNet2 + lossNet3\n",
        "    loss.backward()\n",
        "    #torch.autograd.backward([lossNet, lossNet2, lossNet3])\n",
        "\n",
        "    # optimize all models\n",
        "    o3.step()\n",
        "    o2.step()\n",
        "    o1.step()\n",
        "\n",
        "    # print loss statistics\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  # print loss stats for each epoch\n",
        "  print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / i))\n",
        "\n",
        "  ### define plot\n",
        "  plt.xlabel('loss')\n",
        "  plt.ylabel('epochs')\n",
        "  plt.title('loss function')\n",
        "  plt.plot(running_loss/i, epoch+1)\n",
        "  running_loss = 0.0\n",
        "\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "plt.show()\n",
        "\n",
        "########################################################################\n",
        "# Let's quickly save our trained model:\n",
        "\n",
        "PATH = '/content/drive/MyDrive/ColabProjects/final_project.pth'\n",
        "torch.save(net.state_dict(), PATH)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-4z-NBAM_d2",
        "outputId": "43b64974-b856-4a62-e48d-93611198f10d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 1911 test images: 43 %\n",
            "Accuracy for class Agaricus is: 58.5%\n",
            "Accuracy for class Amanita is: 37.3%\n",
            "Accuracy for class Boletus is: 70.7%\n",
            "Accuracy for class Cortinarius is: 32.7%\n",
            "Accuracy for class Entoloma is: 30.4%\n",
            "Accuracy for class Exidia is: 66.7%\n",
            "Accuracy for class Hygrocybe is: 68.5%\n",
            "Accuracy for class Inocybe is: 24.2%\n",
            "Accuracy for class Lactarius is: 27.5%\n",
            "Accuracy for class Pluteus is: 12.4%\n",
            "Accuracy for class Russula is: 51.6%\n",
            "Accuracy for class Suillus is: 18.0%\n",
            "F1 0.33335320168962707 \n",
            "Precision 0.35703530533462496 \n",
            "Recall 0.36302797731369174 \n",
            "F1 Beta 0.33335320168962707\n"
          ]
        }
      ],
      "source": [
        "########################################################################\n",
        "# 5. Test the trained network on the test data\n",
        "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "batch_size = 20\n",
        "PATH = '/content/drive/MyDrive/ColabProjects/final_project-3branch-80E-20B.pth'\n",
        "net.load_state_dict(torch.load(PATH))\n",
        "\n",
        "dataset = torchvision.datasets.ImageFolder(root='/content/datasets/Mushrooms_3dataset(9528)/test', transform=transform1)\n",
        "testloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,shuffle=True, num_workers=4)\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "myf1 = 0\n",
        "myprecision = 0\n",
        "myrecall = 0\n",
        "myfbeta = 0\n",
        "correct = 0\n",
        "total = 0\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    inputs, labels = data\n",
        "    if torch.cuda.is_available():\n",
        "      inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    outputs1 = net(inputs)\n",
        "    outputs = outputs1\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "    # calculate f1 score\n",
        "    myf1 += f1_score(labels.cpu(), predictions.cpu(), average=\"macro\")\n",
        "    mystuff = precision_recall_fscore_support(labels.cpu(), predictions.cpu(), average='macro', zero_division=0)\n",
        "    myprecision += mystuff[0]\n",
        "    myrecall += mystuff[1]\n",
        "    myfbeta += mystuff[2]\n",
        "\n",
        "\n",
        "    # collect the correct predictions for all classes\n",
        "    total += labels.size(0)\n",
        "    correct += (predictions == labels).sum().item()\n",
        "\n",
        "    # collect the correct predictions for each class\n",
        "    for label, prediction in zip(labels, predictions):\n",
        "      if label == prediction:\n",
        "          correct_pred[classes[label]] += 1\n",
        "      total_pred[classes[label]] += 1\n",
        "\n",
        "# print accuracy for all classes\n",
        "print('Accuracy of the network on the',len(dataset), 'test images: %d %%' % (\n",
        "        100 * correct / total))\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "  accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "  print(\"Accuracy for class {:5s} is: {:.1f}%\".format(classname,accuracy))\n",
        "\n",
        "# print accuracy\n",
        "divider = len(dataset)/batch_size\n",
        "print('F1',myf1/divider, '\\nPrecision', myprecision/divider, '\\nRecall',myrecall/divider, '\\nF1 Beta', myfbeta/divider)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1dUa7_CFnbA_hHCcKlUTr-JB-Uyw5Ev3d",
      "authorship_tag": "ABX9TyP5qRfHPLPbVF6Ibw2b9lLW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}